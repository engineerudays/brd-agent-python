# ğŸš€ Setup & Execution Guide
## BRD Agent Python - Multi-Agent System

Complete guide to set up and run the BRD to Engineering Artifacts pipeline.

---

## ğŸ“‹ Prerequisites

### Required Software
- **Python 3.11+** - Core runtime
- **pip** - Package manager
- **Git** - Version control (optional)

### Optional Tools
- **curl** - API testing (usually pre-installed)
- **jq** - JSON processor (for pretty-printing responses)
  ```bash
  # macOS
  brew install jq
  
  # Ubuntu/Debian
  sudo apt-get install jq
  ```

### Required API Keys
- **Anthropic API Key** - Get from: https://console.anthropic.com/

### System Requirements
- **OS**: macOS, Linux, or Windows
- **RAM**: 4GB minimum (8GB recommended)
- **Disk**: 1GB free space
- **Network**: Internet access for AI API calls

---

## ğŸ—ï¸ Architecture Quick Reference

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  JSON   â”‚â”€â”€â”€â”€â–¶â”‚  Parser  â”‚â”€â”€â”€â”€â–¶â”‚ Engineering â”‚â”€â”€â”€â”€â–¶â”‚ Project  â”‚
â”‚  BRD    â”‚     â”‚  Agent   â”‚     â”‚    Plan     â”‚     â”‚ Schedule â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚                   â”‚                  â”‚
              Input Normalizer      LLM Agent          LLM Agent
                                        
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                LangGraph Workflow
                              (FastAPI Orchestrator)
                                  Port 8000
```

---

## âš™ï¸ Installation

### Step 1: Clone Repository

```bash
git clone https://github.com/engineerudays/brd-agent-python.git
cd brd-agent-python
```

Or if you already have the repository:
```bash
cd /path/to/brd_agent_python
```

### Step 2: Create Virtual Environment

```bash
# Create virtual environment
python -m venv .venv

# Activate virtual environment
# On macOS/Linux:
source .venv/bin/activate

# On Windows:
.venv\Scripts\activate
```

You should see `(.venv)` prefix in your terminal.

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

This installs:
- **langgraph** - Workflow orchestration
- **anthropic** - Claude AI SDK
- **fastapi** - API framework
- **uvicorn** - ASGI server
- **streamlit** - Web UI
- **plotly** - Gantt charts
- **pandas** - Data processing
- **pydantic** - Data validation
- **pypdf** - PDF parsing
- **python-multipart** - File uploads

### Step 4: Configure Environment

```bash
# Copy template to .env
cp env.template .env

# Edit .env with your API key
nano .env  # or use your preferred editor
```

**Required Configuration:**
```bash
# .env file
ANTHROPIC_API_KEY=sk-ant-your-key-here
```

**âš ï¸ Important:** 
- Replace `sk-ant-your-key-here` with your actual Anthropic API key
- Never commit `.env` to git (it's in `.gitignore`)

### Step 5: Verify Installation

```bash
# Test Python imports
python -c "from src.brd_agent.agents import PlannerAgent; print('âœ“ Agents OK')"
python -c "from src.brd_agent.graph.workflow import create_workflow; print('âœ“ Workflow OK')"
python -c "import anthropic; print('âœ“ Anthropic SDK OK')"
```

---

## ğŸš€ Running the Application

### Start Backend (FastAPI)

**Terminal 1:**
```bash
# Ensure virtual environment is active
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Start the backend server
uvicorn api.main:app --reload --port 8000
```

**Expected Output:**
```
INFO:     Will watch for changes in these directories: ['/path/to/brd_agent_python']
INFO:     Uvicorn running on http://127.0.0.1:8000
INFO:     Started reloader process
```

### Start Frontend (Streamlit)

**Terminal 2:**
```bash
# Navigate to project and activate venv
cd /path/to/brd_agent_python
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Start the frontend
streamlit run frontend/app.py --server.port 8501
```

**Expected Output:**
```
  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://192.168.x.x:8501
```

### Verify Services

```bash
# Check backend health
curl http://localhost:8000/health

# Expected response:
# {"status":"healthy","llm_configured":true}
```

Open in browser: **http://localhost:8501**

---

## ğŸ§ª Testing the Pipeline

### Quick Test - End-to-End

**Option 1: Using the UI**
1. Open http://localhost:8501
2. Select "Load Sample" radio button
3. Click "ğŸš€ Process BRD"
4. Wait 30-60 seconds
5. View results in "Results" and "Timeline" tabs

**Option 2: Using curl**
```bash
# Send a test BRD to the API
curl -X POST http://localhost:8000/api/process-brd \
  -H "Content-Type: application/json" \
  -d '{
    "project": {
      "name": "Test Project",
      "description": "A simple test project"
    },
    "features": [
      {
        "id": "F001",
        "name": "User Login",
        "priority": "High"
      }
    ]
  }' | jq
```

### Check Generated Outputs

```bash
# Engineering plans
ls -lh sample_inputs/outputs/engineering_plans/

# Project schedules
ls -lh sample_inputs/outputs/project_schedules/
```

---

## ğŸ”§ Configuration Options

### Environment Variables

| Variable | Required | Description | Default |
|----------|----------|-------------|---------|
| `ANTHROPIC_API_KEY` | Yes | Your Anthropic API key | - |
| `DEFAULT_MODEL` | No | Claude model to use | `claude-sonnet-4-20250514` |
| `OUTPUT_DIR` | No | Directory for artifacts | `sample_inputs/outputs` |

### Frontend Configuration

Edit `frontend/config.py`:

```python
# API endpoint (change if backend runs on different port)
ORCHESTRATOR_URL = "http://localhost:8000/api/process-brd"

# Request timeout (seconds)
TIMEOUT = 180

# Retry settings
MAX_RETRIES = 3
RETRY_DELAY = 2.0
```

---

## ğŸ“ Project Structure

```
brd_agent_python/
â”œâ”€â”€ api/                      # FastAPI services
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # Orchestrator API
â”‚   â””â”€â”€ pdf_parser.py        # PDF parsing endpoints
â”œâ”€â”€ frontend/                 # Streamlit UI
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py               # Main application
â”‚   â”œâ”€â”€ utils.py             # Helper functions
â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â””â”€â”€ requirements.txt     # Frontend deps (subset)
â”œâ”€â”€ src/brd_agent/           # Core library
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agents/              # Agent implementations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py          # Abstract base agent
â”‚   â”‚   â”œâ”€â”€ parser.py        # Input normalizer
â”‚   â”‚   â”œâ”€â”€ planner.py       # Engineering plan agent
â”‚   â”‚   â””â”€â”€ scheduler.py     # Project schedule agent
â”‚   â”œâ”€â”€ graph/               # LangGraph workflow
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ state.py         # Pipeline state
â”‚   â”‚   â””â”€â”€ workflow.py      # Workflow definition
â”‚   â”œâ”€â”€ models/              # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ brd.py           # BRD models
â”‚   â”‚   â”œâ”€â”€ plan.py          # Engineering plan models
â”‚   â”‚   â””â”€â”€ schedule.py      # Schedule models
â”‚   â”œâ”€â”€ prompts/             # AI prompts (future)
â”‚   â”œâ”€â”€ services/            # External services
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ llm.py           # LLM abstraction
â”‚   â””â”€â”€ config.py            # App configuration
â”œâ”€â”€ sample_inputs/           # Test data
â”‚   â”œâ”€â”€ brds/                # Sample BRD files
â”‚   â””â”€â”€ outputs/             # Generated artifacts
â”‚       â”œâ”€â”€ engineering_plans/
â”‚       â””â”€â”€ project_schedules/
â”œâ”€â”€ tests/                   # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ unit/
â”œâ”€â”€ .env                     # Environment variables (create this)
â”œâ”€â”€ env.template             # Environment template
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ README.md                # Project overview
â”œâ”€â”€ SETUP.md                 # This file
â”œâ”€â”€ USER_GUIDE.md            # End-user documentation
â”œâ”€â”€ API_REFERENCE.md         # API documentation
â””â”€â”€ ARCHITECTURE.md          # System design
```

---

## ğŸ› ï¸ Common Commands

### Service Management

```bash
# Start backend (development mode with auto-reload)
uvicorn api.main:app --reload --port 8000

# Start frontend
streamlit run frontend/app.py --server.port 8501

# Stop services
# Press Ctrl+C in each terminal
```

### Package Management

```bash
# Activate virtual environment
source .venv/bin/activate

# Install new package
pip install <package-name>

# Update requirements.txt
pip freeze > requirements.txt

# Install from requirements
pip install -r requirements.txt
```

### Health Checks

```bash
# Backend health
curl http://localhost:8000/health

# Liveness check
curl http://localhost:8000/
```

---

## ğŸ› Troubleshooting

### "ModuleNotFoundError: No module named 'brd_agent'"

**Cause**: Virtual environment not activated or package not installed

**Solution**:
```bash
# Activate venv
source .venv/bin/activate

# Reinstall
pip install -r requirements.txt
```

### "Error: ANTHROPIC_API_KEY not set"

**Cause**: Missing or invalid API key

**Solution**:
```bash
# Check .env file exists
cat .env

# Verify key format (starts with sk-ant-)
# If missing, create it:
echo "ANTHROPIC_API_KEY=sk-ant-your-key-here" > .env
```

### "Port 8000 already in use"

**Cause**: Another process using the port

**Solution**:
```bash
# Find and kill the process
lsof -i :8000
kill -9 <PID>

# Or use a different port
uvicorn api.main:app --port 8001
```

### "Connection refused" from Streamlit

**Cause**: Backend not running or wrong URL

**Solution**:
1. Verify backend is running: `curl http://localhost:8000/health`
2. Check `frontend/config.py` for correct URL
3. Update Orchestrator URL in sidebar if needed

### "Processing failed: Validation errors"

**Cause**: LLM output doesn't match schema

**Solution**:
1. Check backend logs for specific errors
2. Try with a simpler BRD
3. Open an issue if persistent

---

## ğŸ”’ Security Notes

1. **API Key Protection**:
   - Never commit `.env` to git
   - Don't share your API key
   - Rotate keys periodically

2. **Local Development Only**:
   - This setup is for local development
   - Don't expose ports to public internet without authentication

3. **Data Privacy**:
   - BRDs may contain confidential information
   - Generated artifacts are stored locally
   - Clear outputs directory when done

---

## ğŸ¯ Next Steps

After successful setup:

1. **Test with Sample BRD**: Use "Load Sample" in UI
2. **Try PDF Upload**: Upload your own BRD PDF
3. **Explore Results**: Check all sections in Results tab
4. **View Timeline**: Interact with Gantt chart
5. **Download Artifacts**: Export plans as JSON

---

## ğŸ“š Additional Resources

- **LangGraph Documentation**: https://langchain-ai.github.io/langgraph/
- **Anthropic API**: https://docs.anthropic.com/
- **FastAPI**: https://fastapi.tiangolo.com/
- **Streamlit**: https://docs.streamlit.io/

---

## ğŸ†˜ Getting Help

1. Check troubleshooting section above
2. Review logs in terminal
3. Open GitHub issue with:
   - Error message
   - Steps to reproduce
   - Environment details

---

**ğŸ‰ You're all set!** Open the Streamlit UI and start processing BRDs.

